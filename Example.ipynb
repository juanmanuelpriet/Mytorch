{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ”¬ MyTorch Master Benchmark: Complete Analysis\n",
                "\n",
                "This notebook performs a comprehensive visual and numerical analysis of the **MyTorch** framework.\n",
                "\n",
                "## ðŸŽ¯ Analytical Objectives\n",
                "1. **Softmax Impact**: Compare CrossEntropy (with Softmax) vs MSE (without Softmax) on classification.\n",
                "2. **Optimization Benchmark**: Performance of SGD, Momentum, and Adam.\n",
                "3. **Topological Resilience**: Testing on 5 diverse 2D datasets.\n",
                "4. **Convergence Metrics**: Which combination is the fastest and most accurate?\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ImportError",
                    "evalue": "cannot import name 'MSELoss' from 'mytorch.nn' (/Users/juanmanuelprieto/Documents/fundamentos-redes-neuronales/tarea-1/HW1P1/mytorch/nn/__init__.py)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-1-848f2c18f79b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mImportError\u001b[0m: cannot import name 'MSELoss' from 'mytorch.nn' (/Users/juanmanuelprieto/Documents/fundamentos-redes-neuronales/tarea-1/HW1P1/mytorch/nn/__init__.py)"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import time, sys, os\n",
                "from sklearn.datasets import make_moons, make_circles, make_blobs\n",
                "\n",
                "SEED = 245573\n",
                "np.random.seed(SEED)\n",
                "sys.path.append(os.getcwd())\n",
                "\n",
                "from mytorch.nn import Sequential, Linear, GeLU, ReLU, Sigmoid, Tanh, CrossEntropyLoss, MSELoss\n",
                "from mytorch.optim import SGD, Adam\n",
                "\n",
                "print(f\"Environment Ready. Analyzing 120 unique experiments (60 Softmax vs 60 No-Softmax).\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_spiral(n=300, noise=0.3):\n",
                "    t = np.sqrt(np.random.rand(n, 1)) * 780 * (2 * np.pi) / 360\n",
                "    dx = -np.cos(t) * t + np.random.randn(n, 1) * noise\n",
                "    dy = np.sin(t) * t + np.random.randn(n, 1) * noise\n",
                "    return np.vstack((np.hstack((dx, dy)), np.hstack((-dx, -dy)))), np.hstack((np.zeros(n), np.ones(n))).astype(int)\n",
                "\n",
                "datasets = {\n",
                "    \"Moons\": make_moons(n_samples=300, noise=0.15, random_state=SEED),\n",
                "    \"Circles\": make_circles(n_samples=300, noise=0.1, factor=0.5, random_state=SEED),\n",
                "    \"Blobs\": make_blobs(n_samples=300, centers=2, cluster_std=1.2, random_state=SEED),\n",
                "    \"Spiral\": generate_spiral(n=200),\n",
                "    \"Noisy\": make_moons(n_samples=300, noise=0.3, random_state=SEED)\n",
                "}\n",
                "\n",
                "def train_model(model, optimizer, criterion, X, y, epochs=250):\n",
                "    Y_oh = np.eye(2)[y]\n",
                "    history = []\n",
                "    start_time = time.time()\n",
                "    for i in range(epochs):\n",
                "        out = model.forward(X)\n",
                "        loss = criterion.forward(out, Y_oh)\n",
                "        history.append(loss)\n",
                "        model.backward(criterion.backward())\n",
                "        optimizer.step()\n",
                "        optimizer.zero_grad()\n",
                "        # Early stopping proxy: if loss is very low, consider it converged\n",
                "        if loss < 0.01: break\n",
                "    \n",
                "    duration = time.time() - start_time\n",
                "    preds = np.argmax(model.forward(X), axis=1)\n",
                "    acc = np.mean(preds == y)\n",
                "    return acc, loss, i+1, duration\n",
                "\n",
                "def get_boundary(model, X):\n",
                "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
                "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
                "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
                "    Z = np.argmax(model.forward(np.c_[xx.ravel(), yy.ravel()]), axis=1).reshape(xx.shape)\n",
                "    return xx, yy, Z"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ§ª Master Experiment: Softmax vs No-Softmax\n",
                "We run 120 experiments to compare results. We record accuracy, final loss, and convergence speed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = []\n",
                "opts_def = [(\"SGD\", lambda m: SGD(m, lr=0.1)), (\"Momentum\", lambda m: SGD(m, lr=0.1, momentum=0.9)), (\"Adam\", lambda m: Adam(m, lr=0.01))]\n",
                "acts_def = [(\"ReLU\", ReLU), (\"GeLU\", GeLU), (\"Sigmoid\", Sigmoid), (\"Tanh\", Tanh)]\n",
                "criteria_def = [(\"CrossEntropy (Softmax)\", CrossEntropyLoss), (\"MSE (No Softmax)\", MSELoss)]\n",
                "\n",
                "for d_name, (X, y) in datasets.items():\n",
                "    print(f\"Processing Dataset: {d_name}...\")\n",
                "    for c_name, c_cls in criteria_def:\n",
                "        for o_name, o_fn in opts_def:\n",
                "            for a_name, a_cls in acts_def:\n",
                "                model = Sequential(Linear(2, 16), a_cls(), Linear(16, 2))\n",
                "                opt = o_fn(model)\n",
                "                crit = c_cls()\n",
                "                acc, loss, epochs, dur = train_model(model, opt, crit, X, y)\n",
                "                results.append({\n",
                "                    \"Dataset\": d_name, \"Loss Function\": c_name, \"Optimizer\": o_name, \n",
                "                    \"Activation\": a_name, \"Accuracy\": acc, \"Final Loss\": loss, \n",
                "                    \"Epochs\": epochs, \"Time (s)\": dur\n",
                "                })\n",
                "\n",
                "df = pd.DataFrame(results)\n",
                "print(\"âœ… Benchmark Complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“Š Summary Metrics Table\n",
                "Top 10 performing combinations across all datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "summary = df.groupby([\"Loss Function\", \"Optimizer\", \"Activation\"]).agg({\"Accuracy\": \"mean\", \"Epochs\": \"mean\", \"Time (s)\": \"mean\"})\n",
                "display(summary.sort_values(\"Accuracy\", ascending=False).head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŒ€ Convergence Speed Analysis\n",
                "How many epochs does it take for each optimizer/loss combination to reach steady state?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pivot_speed = df.pivot_table(index=\"Dataset\", columns=[\"Loss Function\", \"Optimizer\"], values=\"Epochs\", aggfunc=\"mean\")\n",
                "plt.figure(figsize=(12, 6))\n",
                "pivot_speed.plot(kind=\"bar\", ax=plt.gca())\n",
                "plt.title(\"Convergence Speed (Epochs) per Configuration\")\n",
                "plt.ylabel(\"Epochs\")\n",
                "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ¨ Visual Atlas: Softmax Impact (CrossEntropy vs MSE)\n",
                "Visualizing the spiral dataset specifically."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "d_name = \"Spiral\"\n",
                "X, y = datasets[d_name]\n",
                "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
                "plt.suptitle(f\"Impact of Softmax on Decision Boundaries (Adam Optimizer) - Dataset: {d_name}\", fontsize=20, y=1.02)\n",
                "\n",
                "for r, (c_name, c_cls) in enumerate(criteria_def):\n",
                "    for c, (a_name, a_cls) in enumerate(acts_def):\n",
                "        model = Sequential(Linear(2, 16), a_cls(), Linear(16, 2))\n",
                "        train_model(model, Adam(model, lr=0.01), c_cls(), X, y)\n",
                "        xx, yy, Z = get_boundary(model, X)\n",
                "        ax = axes[r, c]\n",
                "        ax.contourf(xx, yy, Z, alpha=0.5, cmap='Spectral')\n",
                "        ax.scatter(X[:, 0], X[:, 1], c=y, s=10, cmap='Spectral', edgecolors='k')\n",
                "        ax.set_title(f\"{c_name}\\nAct: {a_name}\")\n",
                "        ax.set_xticks([]); ax.set_yticks([])\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
